{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LineageOT benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/aforr/LineageOT@master cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from ott.geometry.geometry import Geometry\n",
    "from ott.geometry.pointcloud import PointCloud\n",
    "from jax import numpy as jnp\n",
    "import seaborn as sns\n",
    "\n",
    "from time import perf_counter\n",
    "from moscot import FusedGW, Regularized, GW\n",
    "import pickle\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ot\n",
    "\n",
    "import lineageot.simulation as sim\n",
    "import lineageot.evaluation as sim_eval\n",
    "import lineageot.inference as sim_inf\n",
    "\n",
    "from typing import Literal, Optional, Sequence, Dict\n",
    "import traceback\n",
    "from collections import namedtuple, defaultdict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnt = namedtuple(\"bnt\", \"tmat early_cost late_cost norm_diff converged time\")\n",
    "stn = namedtuple(\"sim\",\n",
    "                 \"ancestor_info \"\n",
    "                 \"rna_arrays \"\n",
    "                 \"true_coupling \"\n",
    "                 \"true_distances \"\n",
    "                 \"barcode_arrays \"\n",
    "                 \"fitted_distances \"\n",
    "                 \"ec_scale lc_scale \"\n",
    "                 \"early_time_rna_cost \"\n",
    "                 \"late_time_rna_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lot_annotate(fitted_tree: nx.DiGraph, barcodes: np.ndarray, time: float, rate_estimate=None):\n",
    "    sim_inf.add_leaf_barcodes(fitted_tree, barcodes)\n",
    "    sim_inf.add_leaf_times(fitted_tree, time)\n",
    "\n",
    "    # Estimating a uniform mutation rate for all target sites\n",
    "    if rate_estimate is None:\n",
    "        rate_estimate = sim_inf.rate_estimator(barcodes, time)\n",
    "    sim_inf.annotate_tree(fitted_tree, \n",
    "                          rate_estimate*np.ones(barcodes.shape[1]),\n",
    "                          time_inference_method = 'least_squares')\n",
    "    \n",
    "    \n",
    "# root is included twice in LOT code, causes errors with NetworkX\n",
    "def _internal_nodes_fixed(tree):\n",
    "    \"\"\"\n",
    "    Returns a list of the non-leaf nodes of a tree\n",
    "    \"\"\"\n",
    "    import inspect\n",
    "    \n",
    "    curframe = inspect.currentframe()\n",
    "    calframe = inspect.getouterframes(curframe, 2)\n",
    "    caller = calframe[1][3]\n",
    "    \n",
    "    nodes = [node for node in tree if tree.degree(node) >= 2]\n",
    "    nodes.sort(key=lambda n: \"zzzzzzz\" if n == 'root' else str(n))\n",
    "    if caller == 'add_times':\n",
    "        nodes = [n for n in nodes if n != \"root\"]\n",
    "                \n",
    "    return nodes\n",
    "\n",
    "\n",
    "# monkeypatched because our tree has 'root' somehow inside and it's problematic with the sort\n",
    "# uncomment for estim='lot'\n",
    "# sim_inf.get_internal_nodes = _internal_nodes_fixed\n",
    "\n",
    "\n",
    "def cassiopeia_distances(barcodes, solver='hybrid', estim='mle',\n",
    "                         time: float = 1.0,\n",
    "                         rate_estimate=None,\n",
    "                         bayesian_estimator_kwargs={},\n",
    "                         only_tree=False,\n",
    "                         hybrid_solver_kwargs={}, **kwargs):\n",
    "    import cassiopeia as cas\n",
    "    # pip install gurobipy  # for hybrid solver\n",
    "    # if too big a problem, it raises:\n",
    "    # GurobiError: Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license\n",
    "    \n",
    "    n = barcodes.shape[0]\n",
    "    barcodes = pd.DataFrame(barcodes, index=map(str, range(n)))\n",
    "    tree = cas.data.CassiopeiaTree(character_matrix=barcodes)\n",
    "    \n",
    "    # for ILPSolver\n",
    "    kwargs.setdefault(\"convergence_time_limit\", 600)  # 10mins\n",
    "    kwargs.setdefault(\"maximum_potential_graph_layer_size\", 10000)\n",
    "    \n",
    "    if estim == 'bayesian':\n",
    "        print(\"Setting solver to neighbor joining\")\n",
    "        solver = 'nj'\n",
    "    \n",
    "    if solver == 'nj':\n",
    "        solver = cas.solver.NeighborJoiningSolver(add_root=True)\n",
    "    elif solver == 'greedy':\n",
    "        solver = cas.solver.VanillaGreedySolver()\n",
    "    elif solver == 'ilp':\n",
    "        solver = cas.solver.ILPSolver(weighted=False, seed=1234, **kwargs)\n",
    "    elif solver == 'hybrid':\n",
    "        ts = cas.solver.VanillaGreedySolver()\n",
    "        bs = cas.solver.ILPSolver(weighted=False, seed=1234, **kwargs)\n",
    "        solver = cas.solver.HybridSolver(top_solver=ts, bottom_solver=bs, **hybrid_solver_kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(solver)\n",
    "        \n",
    "    solver.solve(tree, collapse_mutationless_edges=estim != 'bayesian')\n",
    "    if only_tree:\n",
    "        G = deepcopy(tree._CassiopeiaTree__network)\n",
    "        G = nx.relabel_nodes(G, dict(zip(map(str, range(n)), range(n))))\n",
    "        root = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "        assert len(root) == 1\n",
    "        root = root[0]\n",
    "        G = nx.relabel_nodes(G, {root: \"root\"})\n",
    "        return tree, G, None\n",
    "    \n",
    "    if estim == 'mle':\n",
    "        estim = cas.tools.branch_length_estimator.IIDExponentialMLE()\n",
    "        estim.estimate_branch_lengths(tree)\n",
    "    elif estim == 'bayesian':\n",
    "        # root must have 1 child\n",
    "        # otherwise, must be a full binary tree\n",
    "        root = tree.root\n",
    "        tree._CassiopeiaTree__add_node(\"synroot\")\n",
    "        tree._CassiopeiaTree__add_edge(\"synroot\", root)\n",
    "        tree._CassiopeiaTree__cache['root'] = 'synroot'\n",
    "        tree.reconstruct_ancestral_characters()\n",
    "        # tree.set_character_states(\"synroot\", [])\n",
    "        # tree._CassiopeiaTree__network.nodes[\"synroot\"]['character_states'] = []\n",
    "        estim = cas.tools.branch_length_estimator.IIDExponentialBayesian(**bayesian_estimator_kwargs)\n",
    "        estim.estimate_branch_lengths(tree)\n",
    "        tree._CassiopeiaTree__remove_node(\"synroot\")\n",
    "        tree._CassiopeiaTree__cache['root'] = root\n",
    "    elif estim == 'lot':\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError(estim)\n",
    "        \n",
    "    G = deepcopy(tree._CassiopeiaTree__network)\n",
    "    G = nx.relabel_nodes(G, dict(zip(map(str, range(n)), range(n))))\n",
    "    root = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    assert len(root) == 1\n",
    "    root = root[0]\n",
    "    G = nx.relabel_nodes(G, {root: \"root\"})\n",
    "    if estim == 'lot':\n",
    "        lot_annotate(G, barcodes.values, time=time, rate_estimate=rate_estimate)\n",
    "        return tree, G, sim_inf.compute_tree_distances(G)\n",
    "    \n",
    "    sim_inf.add_division_times_from_vertex_times(G, current_node='root')\n",
    "    G = sim_inf.add_times_to_edges(G)\n",
    "    # G = sim_inf.add_inverse_times_to_edges(G)\n",
    "    \n",
    "    return tree, G, sim_inf.compute_tree_distances(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geometry(cost_matrix: np.ndarray, scale='max') -> Geometry:\n",
    "    cost_matrix = jnp.array(cost_matrix)\n",
    "    if scale is None:\n",
    "        pass\n",
    "    elif scale == 'max':\n",
    "        cost_matrix /= cost_matrix.max()\n",
    "        assert cost_matrix.max() == 1.0\n",
    "    elif scale == 'mean':\n",
    "        cost_matrix /= np.mean(cost_matrix)\n",
    "    elif scale == 'median':\n",
    "        cost_matrix /= np.median(cost_matrix)\n",
    "    else:\n",
    "        raise NotImplementedError(scale)\n",
    "        \n",
    "    assert (cost_matrix >= 0).all()\n",
    "    return Geometry(cost_matrix=cost_matrix)\n",
    "\n",
    "\n",
    "def fgw_solver(C1, C2, C12, alpha=0, epsilon=1e-2, loss_fun='square_loss',\n",
    "              p=None, q=None, max_iterations=100, rtol=1e-9, atol=1e-9, verbose=False):\n",
    "    \n",
    "    from ot.gromov import init_matrix, gwggrad, gwloss\n",
    "    \n",
    "    assert 0 <= alpha <= 1, alpha\n",
    "    \n",
    "    if p is None:\n",
    "        p = np.ones((C1.shape[0],), dtype=np.float64) / C1.shape[0]\n",
    "    if q is None:\n",
    "        q = np.ones((C2.shape[0],), dtype=np.float64) / C2.shape[0]\n",
    "\n",
    "    solver = ot.sinkhorn if epsilon >= 0.1 else ot.bregman.sinkhorn_epsilon_scaling\n",
    "    C1 = np.asarray(C1, dtype=np.float64)\n",
    "    C2 = np.asarray(C2, dtype=np.float64)\n",
    "    \n",
    "    if alpha == 0:\n",
    "        C12 = np.asarray(C12, dtype=np.float64)\n",
    "        return solver(p, q, C12, reg=epsilon, numItermax=max_iterations, stopThr=rtol)\n",
    "    if alpha == 1:\n",
    "        return ot.gromov.entropic_gromov_wasserstein(C1, C2, p=p, q=q, loss_fun=loss_fun, epsilon=epsilon, tol=rtol)\n",
    "\n",
    "    C12 = np.asarray(C12, dtype=np.float64)\n",
    "    C12 = (1 - alpha) * C12\n",
    "    f_val = 0\n",
    "    T = np.outer(p, q)\n",
    "    constC, hC1, hC2 = init_matrix(C1, C2, p, q, loss_fun)\n",
    "    \n",
    "    \n",
    "    fmt = \"{:5s}|{:12s}|{:8s}|{:8s}\"\n",
    "    if verbose:\n",
    "        print(\n",
    "            fmt.format(\n",
    "                \"It.\",\n",
    "                \"Loss\",\n",
    "                \"Rel. loss   \",\n",
    "                \"Abs. loss   \",\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            + \"-\" * 83\n",
    "        )\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        old_fval = f_val\n",
    "\n",
    "        # compute the gradient\n",
    "        tens = C12 + alpha * gwggrad(constC, hC1, hC2, T)\n",
    "        T = solver(p, q, tens, reg=epsilon)\n",
    "        \n",
    "        f_val = gwloss(constC, hC1, hC2, T)\n",
    "        abs_delta_fval = abs(f_val - old_fval)\n",
    "        relative_delta_fval = abs_delta_fval / abs(f_val)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"{i + 1:5d}|{f_val:8e}|{relative_delta_fval:8e}|{abs_delta_fval:8e}\"\n",
    "            )\n",
    "        \n",
    "        if relative_delta_fval <= rtol or abs_delta_fval <= atol:\n",
    "            break\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sim(flow_type: Literal['bifurcation', 'convergent', 'partial_convergent', 'mistmatched_clusters'],\n",
    "             seed: int = 257, plot: bool = True, **kwargs):\n",
    "    print(seed)\n",
    "    fpath = f\"{flow_type}_{seed}_sim.pickle\"\n",
    "    if os.path.isfile(fpath):\n",
    "        try:\n",
    "            with open(fpath, \"rb\") as fin:\n",
    "                return stn(*pickle.load(fin))\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    start = perf_counter()\n",
    "    np.random.seed(seed) \n",
    "    if flow_type == 'bifurcation':\n",
    "        timescale = 1\n",
    "    else:\n",
    "        timescale = 100\n",
    "\n",
    "    x0_speed = 1/timescale\n",
    "    sim_params = sim.SimulationParameters(division_time_std = 0.01*timescale,\n",
    "                                          flow_type = flow_type,\n",
    "                                          x0_speed = x0_speed,\n",
    "                                          mutation_rate = 1/timescale,\n",
    "                                          mean_division_time = 1.1*timescale,\n",
    "                                          timestep = 0.001*timescale,\n",
    "                                          **kwargs)\n",
    "\n",
    "    # These parameters can be adjusted freely.\n",
    "    # As is, they replicate the plots in the paper for the fully convergent simulation.\n",
    "    mean_x0_early = 2\n",
    "    time_early = 7.4*timescale # Time when early cells are sampled\n",
    "    time_late = time_early + 4*timescale # Time when late cells are sampled\n",
    "    x0_initial = mean_x0_early -time_early*x0_speed\n",
    "    initial_cell = sim.Cell(np.array([x0_initial, 0, 0]), np.zeros(sim_params.barcode_length))\n",
    "    sample_times = {'early' : time_early, 'late' : time_late}\n",
    "\n",
    "\n",
    "\n",
    "    # Choosing which of the three dimensions to show in later plots\n",
    "    if flow_type == 'mismatched_clusters':\n",
    "        dimensions_to_plot = [1, 2]\n",
    "    else:\n",
    "        dimensions_to_plot = [0, 1]\n",
    "\n",
    "    ## Running the simulation\n",
    "    sample = sim.sample_descendants(initial_cell.deepcopy(), time_late, sim_params)\n",
    "\n",
    "    # Extracting trees and barcode matrices\n",
    "    true_trees = {'late': sim_inf.list_tree_to_digraph(sample)}\n",
    "    true_trees['late'].nodes['root']['cell'] = initial_cell\n",
    "    true_trees['early'] = sim_inf.truncate_tree(true_trees['late'], sample_times['early'], sim_params)\n",
    "\n",
    "    # Computing the ground-truth coupling\n",
    "    true_coupling = sim_inf.get_true_coupling(true_trees['early'], true_trees['late'])\n",
    "    \n",
    "    data_arrays = {'late': sim_inf.extract_data_arrays(true_trees['late']),\n",
    "                   'early': sim_inf.extract_data_arrays(true_trees['early'])}\n",
    "    rna_arrays = {'late': data_arrays['late'][0]}\n",
    "    barcode_arrays = {'early': data_arrays['early'][1], 'late': data_arrays['late'][1]}\n",
    "\n",
    "    rna_arrays['early'] = sim_inf.extract_data_arrays(true_trees['early'])[0]\n",
    "    num_cells = {'early': rna_arrays['early'].shape[0], 'late': rna_arrays['late'].shape[0]}\n",
    "\n",
    "    print(\"Times:\", sample_times)\n",
    "    print(\"Number of cells:\", num_cells)\n",
    "    \n",
    "        # Creating a copy of the true tree for use in LineageOT\n",
    "    true_trees['late, annotated'] = copy.deepcopy(true_trees['late'])\n",
    "    sim_inf.add_node_times_from_division_times(true_trees['late, annotated'])\n",
    "\n",
    "    sim_inf.add_nodes_at_time(true_trees['late, annotated'], sample_times['early'])\n",
    "    \n",
    "    if plot:\n",
    "        # Scatter plot of cell states\n",
    "        cmap = \"coolwarm\"\n",
    "        colors = [plt.get_cmap(cmap)(0), plt.get_cmap(cmap)(256)]\n",
    "        for a,label, c in zip([rna_arrays['early'], rna_arrays['late']], ['Early cells', 'Late cells'], colors):\n",
    "            plt.scatter(a[:, dimensions_to_plot[0]],\n",
    "                        a[:, dimensions_to_plot[1]], alpha = 0.4, label = label, color = c)\n",
    "\n",
    "        plt.xlabel('Gene ' + str(dimensions_to_plot[0] + 1))\n",
    "        plt.ylabel('Gene ' + str(dimensions_to_plot[1] + 1))\n",
    "        plt.legend()\n",
    "        \n",
    "    # Infer ancestor locations for the late cells based on the true lineage tree\n",
    "    observed_nodes = [n for n in sim_inf.get_leaves(true_trees['late, annotated'], include_root=False)]\n",
    "    sim_inf.add_conditional_means_and_variances(true_trees['late, annotated'], observed_nodes)\n",
    "\n",
    "    ancestor_info = {'true tree': sim_inf.get_ancestor_data(true_trees['late, annotated'], sample_times['early'])}\n",
    "    \n",
    "    # True distances\n",
    "    true_distances = {key: sim_inf.compute_tree_distances(true_trees[key]) for key in true_trees}\n",
    "    \n",
    "    rate_estimate = sim_inf.rate_estimator(barcode_arrays['late'], sample_times['late'])\n",
    "\n",
    "    print(\"Fraction unmutated barcodes: \", {key:np.sum(barcode_arrays[key] == 0)/barcode_arrays[key].size\n",
    "                                            for key in barcode_arrays})\n",
    "    print(\"Rate estimate: \", rate_estimate)\n",
    "    print(\"True rate: \", sim_params.mutation_rate / sim_params.barcode_length)\n",
    "    print(\"Rate accuracy: \", rate_estimate*sim_params.barcode_length/sim_params.mutation_rate)\n",
    "    \n",
    "    # Compute Hamming distance matrices for neighbor joining\n",
    "\n",
    "    hamming_distances_with_roots = {\n",
    "        'early': sim_inf.barcode_distances(np.concatenate([barcode_arrays['early'],\n",
    "                                                           np.zeros([1,sim_params.barcode_length])])),\n",
    "        'late': sim_inf.barcode_distances(np.concatenate([barcode_arrays['late'],\n",
    "                                                          np.zeros([1,sim_params.barcode_length])]))\n",
    "    }\n",
    "    fitted_tree = sim_inf.neighbor_join(hamming_distances_with_roots['late'])\n",
    "    fitted_tree_early = sim_inf.neighbor_join(hamming_distances_with_roots['early'])\n",
    "    \n",
    "    # Annotate fitted tree with internal node times\n",
    "\n",
    "    sim_inf.add_leaf_barcodes(fitted_tree, barcode_arrays['late'])\n",
    "    sim_inf.add_leaf_x(fitted_tree, rna_arrays['late'])\n",
    "    sim_inf.add_leaf_times(fitted_tree, sample_times['late'])\n",
    "    sim_inf.annotate_tree(fitted_tree,\n",
    "                          rate_estimate*np.ones(sim_params.barcode_length),\n",
    "                          time_inference_method = 'least_squares')\n",
    "    \n",
    "    # Add inferred ancestor nodes and states\n",
    "    sim_inf.add_node_times_from_division_times(fitted_tree)\n",
    "    sim_inf.add_nodes_at_time(fitted_tree, sample_times['early'])\n",
    "    observed_nodes = [n for n in sim_inf.get_leaves(fitted_tree, include_root = False)]\n",
    "    sim_inf.add_conditional_means_and_variances(fitted_tree, observed_nodes)\n",
    "    ancestor_info['fitted tree'] = sim_inf.get_ancestor_data(fitted_tree, sample_times['early'])\n",
    "    \n",
    "    fitted_tree_distances = sim_inf.compute_tree_distances(fitted_tree)\n",
    "    hamming_distances_late = hamming_distances_with_roots['late'] / rate_estimate\n",
    "    \n",
    "    \n",
    "    sim_inf.add_leaf_barcodes(fitted_tree_early, barcode_arrays['early'])\n",
    "    sim_inf.add_leaf_x(fitted_tree_early, rna_arrays['early'])\n",
    "    sim_inf.add_leaf_times(fitted_tree_early, sample_times['early'])\n",
    "    sim_inf.annotate_tree(fitted_tree_early,\n",
    "                          rate_estimate*np.ones(sim_params.barcode_length),\n",
    "                          time_inference_method = 'least_squares')\n",
    "    sim_inf.add_node_times_from_division_times(fitted_tree_early)\n",
    "    \n",
    "    fitted_tree_early_distances = sim_inf.compute_tree_distances(fitted_tree_early)\n",
    "\n",
    "    \n",
    "    # Add inferred ancestor nodes and states\n",
    "    sim_inf.add_node_times_from_division_times(fitted_tree)\n",
    "    sim_inf.add_nodes_at_time(fitted_tree, sample_times['early'])\n",
    "\n",
    "    end = perf_counter() - start\n",
    "    print(f\"Time: {end}\")\n",
    "    \n",
    "    early_time_rna_cost = ot.utils.dist(rna_arrays['early'], sim_inf.extract_ancestor_data_arrays(true_trees['late'], sample_times['early'], sim_params)[0])\n",
    "    late_time_rna_cost = ot.utils.dist(rna_arrays['late'], rna_arrays['late'])\n",
    "    \n",
    "    fd = {}\n",
    "    _, _, fd['early'] = cassiopeia_distances(barcode_arrays['early'].astype(int),\n",
    "                                             solver='hybrid', estim='mle',\n",
    "                                             only_tree=False,\n",
    "                                             hybrid_solver_kwargs={\"cell_cutoff\": 80, \"threads\": 1})\n",
    "    _, _, fd['late'] = cassiopeia_distances(barcode_arrays['late'].astype(int),\n",
    "                                            solver='hybrid', estim='mle',\n",
    "                                            only_tree=False,\n",
    "                                            hybrid_solver_kwargs={\"cell_cutoff\": 80, \"threads\": 1})\n",
    "    \n",
    "    indep = np.ones(true_coupling.shape) / true_coupling.size\n",
    "    ind_ancestor_error = sim_inf.OT_cost(indep, early_time_rna_cost)\n",
    "    ind_descendant_error = sim_inf.OT_cost(sim_eval.expand_coupling(indep,\n",
    "                                                                    true_coupling,\n",
    "                                                                    late_time_rna_cost),\n",
    "                                           late_time_rna_cost)\n",
    "    \n",
    "    res = stn(ancestor_info, rna_arrays, true_coupling, true_distances,\n",
    "              barcode_arrays, fd,\n",
    "              ind_ancestor_error, ind_descendant_error,\n",
    "              early_time_rna_cost, late_time_rna_cost)\n",
    "    \n",
    "    with open(fpath, \"wb\") as fout:\n",
    "        pickle.dump(tuple(res), fout)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_moscot(sim: stn, *, alpha: float, epsilon: Optional[float] = None,\n",
    "                     tree_type: str = 'fitted tree', scale: str = \"max\", **kwargs):\n",
    "    print(tree_type)\n",
    "    scale_fn = {\n",
    "        \"max\": jnp.max,\n",
    "        \"mean\": jnp.mean,\n",
    "        \"median\": jnp.median,\n",
    "        None: None,\n",
    "    }\n",
    "    \n",
    "    if tree_type == 'fitted tree':\n",
    "        e = sim.fitted_distances['early']\n",
    "        l = sim.fitted_distances['late']\n",
    "    elif tree_type == 'true tree':\n",
    "        e = sim.true_distances['early']\n",
    "        l = sim.true_distances['late']\n",
    "    else:\n",
    "        raise NotImplementedError(tree_type)\n",
    "    e = create_geometry(e, scale=scale)\n",
    "    l = create_geometry(l, scale=scale)\n",
    "    joint = create_geometry(ot.utils.dist(sim.rna_arrays['early'], sim.rna_arrays['late']), scale=scale)\n",
    "    \n",
    "    max_iterations = kwargs.pop(\"max_iterations\", 20)\n",
    "    rtol = kwargs.pop(\"rtol\", 1e-6)\n",
    "    atol = kwargs.pop(\"atol\", 1e-6)\n",
    "    \n",
    "    start = perf_counter()\n",
    "    if alpha == 0:\n",
    "        u = Regularized(epsilon=epsilon)\n",
    "        u.fit(joint)\n",
    "        tmat = np.asarray(u.matrix)\n",
    "        conv = [u.converged]\n",
    "    elif alpha == 1:\n",
    "        gw = GW(epsilon=epsilon)\n",
    "        gw.fit(e, l)\n",
    "        tmat = np.asarray(gw.matrix)\n",
    "        conv = gw.converged_sinkhorn\n",
    "    else:\n",
    "        fgw = FusedGW(alpha=alpha, epsilon=epsilon, **kwargs)\n",
    "        fgw.fit(e, l, joint, linesearch=False, verbose=False,\n",
    "                scale_fn=scale_fn[scale],\n",
    "                max_iterations=max_iterations, rtol=rtol, atol=atol)\n",
    "        tmat = np.asarray(fgw.matrix)\n",
    "        conv = fgw.converged_sinkhorn\n",
    "        \n",
    "    time = perf_counter() - start\n",
    "    print(f\"Time: {time}\")\n",
    "    \n",
    "    if not np.all(np.isfinite(tmat)):\n",
    "        raise AssertionError(\"Convergence issue - not all values are finite.\")\n",
    "    \n",
    "    early_cost = float(sim_inf.OT_cost(tmat, sim.early_time_rna_cost))\n",
    "    late_cost = float(sim_inf.OT_cost(sim_eval.expand_coupling(tmat, sim.true_coupling, sim.late_time_rna_cost),\n",
    "                                                               sim.late_time_rna_cost))\n",
    "    early_cost /= sim.ec_scale\n",
    "    late_cost /= sim.lc_scale\n",
    "    norm_diff = np.linalg.norm(tmat - sim.true_coupling)\n",
    "        \n",
    "    return bnt(tmat, early_cost, late_cost, norm_diff, conv, time)\n",
    "\n",
    "\n",
    "def benchmark_lineageOT(sim: stn, *, epsilon: float, tree_type: str = 'fitted tree', **kwargs):\n",
    "    print(tree_type)\n",
    "    cmat = ot.utils.dist(sim.rna_arrays['early'], sim.ancestor_info[tree_type][0]) @ np.diag(sim.ancestor_info[tree_type][1] ** (-1))\n",
    "    \n",
    "    # Epsilon scaling is more robust at smaller epsilon, but slower than simple sinkhorn\n",
    "    f = ot.sinkhorn if epsilon >= 0.1 else ot.bregman.sinkhorn_epsilon_scaling\n",
    "    start = perf_counter()\n",
    "    tmat = f([], [], cmat, epsilon * np.mean(sim.ancestor_info[tree_type][1] ** (-1)), **kwargs)\n",
    "    time = perf_counter() - start\n",
    "    \n",
    "    early_cost = float(sim_inf.OT_cost(tmat, sim.early_time_rna_cost))\n",
    "    late_cost = float(sim_inf.OT_cost(sim_eval.expand_coupling(tmat, sim.true_coupling, sim.late_time_rna_cost),\n",
    "                                                               sim.late_time_rna_cost))\n",
    "    \n",
    "    early_cost /= sim.ec_scale\n",
    "    late_cost /= sim.lc_scale\n",
    "    norm_diff = np.linalg.norm(tmat - sim.true_coupling)\n",
    "    \n",
    "    return bnt(tmat, early_cost, late_cost, norm_diff, None, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(sim: stn, *, alphas: Sequence[float], epsilons: Sequence[float], scale: str = \"max\", **kwargs) -> Dict[float, Dict[float, bnt]]:\n",
    "    res = defaultdict(defaultdict)\n",
    "    for alpha in alphas:\n",
    "        for epsilon in epsilons:\n",
    "            try:\n",
    "                print(f\"alpha={alpha}, epsilon={epsilon} scale={scale}\")\n",
    "                res[alpha][epsilon] = benchmark_moscot(sim, alpha=alpha, epsilon=epsilon, scale=scale, **kwargs)\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "                res[alpha][epsilon] = None\n",
    "    \n",
    "    return {a: {e: v for e, v in vs.items()} for a, vs in res.items()}\n",
    "\n",
    "def gridsearch_lineageOT(sim: stn, *, epsilons: Sequence[float], **kwargs) -> Dict[float, Dict[float, bnt]]:\n",
    "    res = defaultdict(defaultdict)\n",
    "    for alpha in [None]:\n",
    "        for epsilon in epsilons:\n",
    "            if epsilon is None:\n",
    "                res[alpha][epsilon] = None\n",
    "                continue\n",
    "            try:\n",
    "                print(f\"alpha={alpha}, epsilon={epsilon}\")\n",
    "                res[alpha][epsilon] = benchmark_lineageOT(sim, epsilon=epsilon, **kwargs)\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "                res[alpha][epsilon] = None\n",
    "    \n",
    "    return {a: {e: v for e, v in vs.items()} for a, vs in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac6774e6fb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'temp6'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtree_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree_type' is not defined"
     ]
    }
   ],
   "source": [
    "seeds = [42, 69, 420, 1337]\n",
    "sim_params = {\"seed\": seeds[0]}\n",
    "# original epsilons\n",
    "epsilons = [None] + sorted([1e-4, 5e-3, 1e-3, 5e-2, 1e-2, 5e-1, 1e-1, 1])\n",
    "alphas = list(np.round(np.linspace(0.0, 1, 21, dtype=np.float64), 2))\n",
    "root = 'temp6'\n",
    "tree_type\n",
    "print(epsilons)\n",
    "print(alphas)\n",
    "len(epsilons), len(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt, tree_type in zip([\"tt\", \"ft\"], ['true tree', 'fitted tree']):\n",
    "    for flow_type in [\"bifurcation\"]:  # , \"convergent\", \"partial_convergent\", \"mismatched_clusters\"]:\n",
    "        s = init_sim(flow_type, plot=False, seed=seed, **sim_params)\n",
    "        for kind in ['lineageOT', 'moscot']:\n",
    "            if kind == 'lineageOT':\n",
    "                fname = f\"{flow_type}_{tt}_lot.pickle\"\n",
    "                res = gridsearch_lineageOT(s, epsilons=epsilons, numItermax=100, stopThr=1e-9,\n",
    "                                           tree_type=tree_type)\n",
    "            else:\n",
    "                fname = f\"{flow_type}_{tt}_{scale}.pickle\"\n",
    "                res = gridsearch(s, alphas=alphas, epsilons=epsilons, scale=scale,\n",
    "                                 tree_type=tree_type,\n",
    "                                 max_iterations=100, rtol=1e-9, atol=1e-9)\n",
    "\n",
    "            with open(f\"{root}/{fname}\", \"wb\") as fout:\n",
    "                pickle.dump(res, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellrank",
   "language": "python",
   "name": "cellrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
